---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

I am currently a 3rd year Ph.D. student at [Gaoling School of Artificial Intelligence (GSAI)](http://ai.ruc.edu.cn/english/index.htm) in Renmin University of China, supervised by [Prof. Rui Yan](https://scholar.google.com/citations?user=eLw6g-UAAAAJ&hl=en). I am dedicated to creating more powerful foundation language models.

# News Within a Year

- *2025.01*: We propose [Autonomy-of-Experts Models](https://arxiv.org/pdf/2501.13074), a new MoE paradigm.

- *2025.01*: One paper is accepted by WWW 2025 oral.

- *2025.01*: One paper is accepted by NAACL 2025 main (short paper).

- *2024.11*: We propose [Cog Attention](https://arxiv.org/pdf/2411.07176) that enables negative attention weights for enhanced expressiveness.

- *2024.11*: I am awarded the 2024 CIE-Tencent Doctoral Student Research Incentive Program (HunYuan Large Language Model Special Project).

- *2024.09*: One paper is accepted by NeurIPS 2024.

- *2024.09*: Two papers are accepted by EMNLP 2024 main conference.

- *2024.09*: We propose that the [development of context copying capacities in LLMs is a special grokking.](https://arxiv.org/pdf/2409.09281)

- *2024.05*: I am awarded the 2024 CCF-Tencent Rhino-Bird Elite Talent Program, mentored by [Ruobing Xie](https://ruobingxie.github.io/).

- *2024.05*: Two papers are accepted by ACL 2024 main conference. One paper is accepted by ACL 2024 findings.

- *2024.04*: One paper is accepted by IJCAI 2024.

- *2024.03*: We thoroughly studied the [mechanisms of factual recall in Transformer-based language models](https://arxiv.org/abs/2403.19521).

# Publications (First Author and First Co-author)

- *PEAR*: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead. **Ang Lv\***, Tao Tan\*, Yining Qian\*, Hongzhan Lin, Songhao Wu, Yongbo Wang, Feng Wang, Jingtong Wu, Xin Lu, Rui Yan. *The Web Conference (WWW'25 **oral**)* [Link](https://arxiv.org/pdf/2409.19745)

- Language Models "Grok" to Copy. **Ang Lv**, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Rui Yan. *Proceedings of the 2025 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL'25 short).* [Link](https://arxiv.org/pdf/2409.09281)

- An Analysis and Mitigation of the Reversal Curse. **Ang Lv\***, Kaiyi Zhang\*, Shufang Xie, Quan Tu, Yuhan Chen, Ji-Rong Wen, Rui Yan. *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP'24).* [Link](https://aclanthology.org/2024.emnlp-main.754/)

- Mixture-of-Modules: Reinventing Transformers as Dynamic Assemblies of Modules. **Ang Lv\***, Zhuocheng Gong\*, Jian Guan, Junxi Yan, Wei Wu, Huishuai Zhang, Minlie Huang, Dongyan Zhao, Rui Yan. *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP'24).* [Link](https://aclanthology.org/2024.emnlp-main.1164/)

- Mixture of In-Context Experts Enhance LLMs’ Long Context Awareness. **Ang Lv\***, Hongzhan Lin\*, Yuhan Chen\*, Chen Zhu, Yang Song, Hengshu Zhu, Rui Yan. *Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS' 24).*

- Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use. **Ang Lv\***, Yuhan Chen\*, Ting-En Lin, Changyu Chen, Yuchuan Wu, Fei Huang, Yongbin Li, Rui Yan. *Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL'24).* [Link](https://aclanthology.org/2024.acl-long.601/)

- Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning. **Ang Lv\***, Kaiyi Zhang\*, Yuhan Chen, Hansen Ha, Tao Xu, Rui Yan. *Findings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL '24 Findings).* [Link](https://aclanthology.org/2024.findings-acl.638/)

- Re-creation of Creations: A New Paradigm for Lyric-to-Melody Generation. **Ang Lv**, Xu Tan, Tao Qin, Tie-Yan Liu, Rui Yan. *The 33th International Joint Conference on Artificial Intelligence (IJCAI'24).* [Link](https://www.ijcai.org/proceedings/2024/0853) 

- DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations. **Ang Lv\***, Jinpeng Li\*, Yuhan Chen, Gao Xing, Ji Zhang, Rui Yan. *Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL'23).* [Link](https://aclanthology.org/2023.acl-long.70/)

- Envisioning Future from the Past: Hierarchical Duality Learning for Multi-Turn Dialogue Generation. **Ang Lv\***, Jinpeng Li\*, Shufang Xie, Rui Yan. *Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL'23 **oral**).* [Link](https://aclanthology.org/2023.acl-long.407/)

- Target-Side Input Augmentation for Sequence to Sequence Generation. **Ang Lv\***, Shufang Xie\*, Yingce Xia, Lijun Wu, Tao Qin, Tie-Yan Liu, Rui Yan. *The 10th International Conference on Learning Representations (ICLR'22).* [Link](https://openreview.net/forum?id=pz1euXohm4H)


# Other Publications

- Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models. Changyu Chen, Xiting Wang, Ting-En Lin, **Ang Lv**, Yuchuan Wu, Xin Gao, Ji-Rong Wen, Rui Yan, Yongbin Li. *Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL'24).* [Link](https://aclanthology.org/2024.acl-long.320/)

# Preprint Papers

- Autonomy-of-Experts Models. **Ang Lv**, Ruobing Xie, Yining Qian, Songhao Wu, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan. *Arxiv*, [Link](https://arxiv.org/pdf/2501.13074)

- More Expressive Attention with Negative Weights. **Ang Lv**, Ruobing Xie, Shuaipeng Li, Jiayi Liao, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan. *Arxiv*, [Link](https://arxiv.org/pdf/2411.07176)

- Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models. **Ang Lv\***, Yuhan Chen\*, Kaiyi Zhang\*, Yulong Wang, Lifeng Liu, Ji-Rong Wen, Jian Xie, Rui Yan. *Arxiv.* [Link](https://arxiv.org/abs/2403.19521)

- GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework. **Ang Lv**, Xu Tan, Peiling Lu, Wei Ye, Shikun Zhang, Jiang Bian, Rui Yan. *Arxiv.* [Link](https://arxiv.org/abs/2305.10841)

# Honors and Awards
- CIE-Tencent Doctoral Student Research Incentive Program (HunYuan Large Language Model Special Project), 1 of 17 selected individuals nationwide（中国电子学会-腾讯博士生科研激励计划 混元大模型专项，全国17人）
- CCF-Tencent Rhino-Bird Elite Talent Program, 2024, 1 of 50 selected individuals nationwide（中国计算机学会-腾讯犀牛鸟精英人才计划，全国50人）
- Supported by the Outstanding Innovative Talents Cultivation Funded Programs 2023 of Renmin University of
China, 2023 (中国人民大学拔尖创新人才)

# Academic Services
- Conference Reviewer: ACL (Area Chair), EMNLP, ICLR, WWW, KDD
- Journal Reviewer: ACM TIST

# Internships
- *2022.09 - 2023.03*, Alibaba Damo Academy, Hangzhou.
- *2023.03 - 2023.09*, Microsoft Research, [Machine Learning Area](https://www.microsoft.com/en-us/research/group/machine-learning-research-group/), mentored by [Xu Tan](https://scholar.google.co.jp/citations?user=tob-U1oAAAAJ&hl=en). Our collaborative efforts are dedicated to the [Muzic project](https://github.com/microsoft/muzic), which currently boasts 4k stars on GitHub.
- *2023.09 - 2024.05*, Tongyi Lab, Alibaba, Beijing.
- *2024.05 - now*, Tencent, Beijing.
